---
kafka_broker_custom_log4j: true

kafka_broker_java_args:
  - "{% if 'GSSAPI' in kafka_broker_sasl_enabled_mechanisms or zookeeper_sasl_protocol in ['kerberos', 'digest'] %}-Djava.security.auth.login.config={{kafka_broker.jaas_file}}{% endif %}"
  - "{% if kafka_broker_jolokia_enabled|bool %}-javaagent:{{jolokia_jar_path}}=port={{kafka_broker_jolokia_port}},host=0.0.0.0{% if kafka_broker_jolokia_ssl_enabled|bool %}{{kafka_broker_jolokia_java_arg_ssl_addon}}{% endif %}{% endif %}"
  - "{% if kafka_broker_jmxexporter_enabled|bool %}-javaagent:{{jmxexporter_jar_path}}={{kafka_broker_jmxexporter_port}}:{{kafka_broker_jmxexporter_config_path}}{% endif %}"
  - "{% if schema_registry_ssl_enabled|bool %}-Djavax.net.ssl.keyStore={{kafka_broker_keystore_path}} -Djavax.net.ssl.trustStore={{kafka_broker_truststore_path}} -Djavax.net.ssl.keyStorePassword={{kafka_broker_keystore_storepass}} -Djavax.net.ssl.trustStorePassword={{kafka_broker_truststore_storepass}}{% endif %}"
  - "{% if kafka_broker_custom_log4j|bool %}-Dlog4j.configuration=file:{{kafka_broker.log4j_file}}{% endif %}"

kafka_broker_custom_java_args: ""
kafka_broker_final_java_args: "{{ kafka_broker_java_args + [ kafka_broker_custom_java_args ] }}"

# Kafka already has LimitNOFILE value set in unit file, empty value will not get written to override.conf
kafka_broker_service_overrides:
  LimitNOFILE:
  User: "{{ kafka_broker_user if kafka_broker_user != kafka_broker_default_user else '' }}"
  Group: "{{ kafka_broker_group if kafka_broker_group != kafka_broker_default_group else '' }}"
kafka_broker_service_environment_overrides:
  KAFKA_HEAP_OPTS: "-Xmx1g"
  KAFKA_OPTS: "{{ kafka_broker_final_java_args | java_arg_build_out }}"

kafka_broker_sysctl:
  vm.swappiness: 1
  vm.dirty_background_ratio: 5
  vm.dirty_ratio: 60

kafka_broker_sysctl_file: /etc/sysctl.conf

kafka_broker_metrics_reporter_enabled: true

kafka_broker_default_interal_replication_factor: "{{ [ groups['kafka_broker'] | length, 3 ] | min }}"

kafka_broker:
  appender_log_path: /var/log/kafka/
  kafka_appender_log_name: server.log
  kafka_appender_max_log_files: 10
  kafka_appender_log_file_size: 100MB
  state_change_appender_log_name: state-change.log
  state_change_appender_max_log_files: 10
  state_change_appender_log_file_size: 100MB
  request_appender_log_name: kafka-request.log
  request_appender_max_log_files: 10
  request_appender_log_file_size: 100MB
  cleaner_appender_log_name: log-cleaner.log
  cleaner_appender_max_log_files: 10
  cleaner_appender_log_file_size: 100MB
  controller_appender_log_name: controller.log
  controller_appender_max_log_files: 10
  controller_appender_log_file_size: 100MB
  authorizer_appender_log_name: kafka-authorizer.log
  authorizer_appender_max_log_files: 10
  authorizer_appender_log_file_size: 100MB
  metadata_appender_log_name: metadata.log
  metadata_appender_max_log_files: 10
  metadata_appender_log_file_size: 100mb
  datadir:
    - /var/lib/kafka/data
  properties:
    group.initial.rebalance.delay.ms: 0
    log.retention.check.interval.ms: 300000
    log.retention.hours: 168
    log.segment.bytes: 1073741824
    num.io.threads: 16
    num.network.threads: 8
    num.partitions: 1
    num.recovery.threads.per.data.dir: 2
    offsets.topic.replication.factor: "{{kafka_broker_default_interal_replication_factor}}"
    socket.receive.buffer.bytes: 102400
    socket.request.max.bytes: 104857600
    socket.send.buffer.bytes: 102400
    transaction.state.log.min.isr: 2
    transaction.state.log.replication.factor: "{{kafka_broker_default_interal_replication_factor}}"
    zookeeper.connection.timeout.ms: 18000
    confluent.license.topic.replication.factor: "{{kafka_broker_default_interal_replication_factor}}"
    confluent.metadata.topic.replication.factor: "{{kafka_broker_default_interal_replication_factor}}"
    confluent.support.metrics.enable: "{{confluent.support.metrics_enabled|bool|lower}}"
    confluent.support.customer.id: "{{confluent.support.customer_id}}"
